{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foundations: Split data into train, validation, and test set\n",
    "\n",
    "Using the Titanic dataset from [this](https://www.kaggle.com/c/titanic/overview) Kaggle competition.\n",
    "\n",
    "In this section, we will split the data into train, validation, and test set in preparation for fitting a basic model in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data\n",
    "\n",
    "_Welcome back, this lesson will be very simple - we're just going to split up our full dataset so we have 60% of it in the training set, 20% in the validation set, and 20% in the test set._\n",
    "\n",
    "_We will import the packages we'll need and reading in our data - again, we're using this `train test split` method we're importing from `sklearn` - that will make our job here **very** easy. And I also want to call out that we're reading in this `titanic cleaned` dataset that we created in the last lesson._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Family_cnt</th>\n",
       "      <th>Cabin_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age     Fare  Family_cnt  Cabin_ind\n",
       "0         0       3    0  22.0   7.2500           1          0\n",
       "1         1       1    1  38.0  71.2833           1          1\n",
       "2         1       3    1  26.0   7.9250           0          0\n",
       "3         1       1    1  35.0  53.1000           1          1\n",
       "4         0       3    0  35.0   8.0500           0          0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "titanic = pd.read_csv('../titanic_cleaned.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train, validation, and test set\n",
    "\n",
    "![Split Data](img/split_data.png)\n",
    "\n",
    "_We start by splitting our data into our features (the fields used to make a prediction) and our labels or target variable (in our case that's whether somebody survived or not)._\n",
    "\n",
    "_Then we will call `train test split` method and first we need to pass in our features, then we'll pass in our labels, we tell it what percent of the dataset we want allocated to the test set, and lastly `random state` (initialization seed for randomizer). Just to reiterate, `train test split` can't handle splitting data into three datasets, it can only do two. So we'll handle this in two steps. Allocate 60% to training and 40% to what it's calling \"test\". Then we will take that 40% and split it in half in a second step and that will give us our 60% training, 20% validation, 20% test set._\n",
    "\n",
    "_Don't forget that the ordering is important. It takes the features and splits it into train and test so the first two outputs are `X train` and `X test`, then it takes the labels and splits that into train and test - `y train` and `y test`.\n",
    "\n",
    "So now you might be wondering why I'm indicating test size of 40%? Well, `train test split` doesn't have the functionality to split into three datasets. So we'll handle this in two steps. Allocate 60% to training and 40% to which it's calling \"test\". Then we will take that 40% and split it in half and that will give us our 60% training, 20% validation, 20% test set._\n",
    "\n",
    "_Then we can just copy that down test set and split it into validation and test. So we will copy and paste down. Change `features` to `X test`, change `labels` to `y test`, and change `test size` to 50%. So we're taking the 40% of the full dataset that we assigned to the test set and we're splitting it in half to create our validation set and test set. Now, lets update the output names. We'll say `X test`, `X val`, `y test`, and `y val`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = titanic.drop('Survived', axis=1)\n",
    "labels = titanic['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Now, lets quickly take a look at the length of each of these datasets to make sure that 60% went to train and 20% to each test and validation. So print out the length of `labels` (full dataset), length of `y train`, length of `y val`, and length of `y test`._\n",
    "\n",
    "_And we can confirm that it's split out the way we expected. We didn't have the right number for test and validation to be exactly equal so there is one more in the validation set but that's not a big deal._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 534 178 179\n"
     ]
    }
   ],
   "source": [
    "print(len(labels), len(y_train), len(y_test), len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out all data\n",
    "\n",
    "_Lastly, lets write these all out so to make sure we're using the exact same training, validation, and test set as we're exploring various algorithms in the next few sections._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('../train_features.csv', index=False)\n",
    "X_val.to_csv('../val_features.csv', index=False)\n",
    "X_test.to_csv('../test_features.csv', index=False)\n",
    "\n",
    "y_train.to_csv('../train_labels.csv', index=False)\n",
    "y_val.to_csv('../val_labels.csv', index=False)\n",
    "y_test.to_csv('../test_labels.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
