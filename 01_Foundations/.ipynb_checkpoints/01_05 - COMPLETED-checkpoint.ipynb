{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foundations: Split data into train, validation, and test set\n",
    "\n",
    "Using the Titanic dataset from [this](https://www.kaggle.com/c/titanic/overview) Kaggle competition.\n",
    "\n",
    "In this section, we will split the data into train, validation, and test set in preparation for fitting a basic model in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data\n",
    "\n",
    "_Welcome back, this lesson will be very simple - we're just going to split up our full dataset so we have 60% of it in the training set, 20% in the validation set, and 20% in the test set. Doing this kind of split will help us evaluate the models and perform model selection using unbiased results._\n",
    "\n",
    "_We will import the packages we'll need and read in our data - we're going to use this `train test split` method imported from `sklearn` - that will make our job here **very** easy. And I also want to call out that we're reading in this `titanic cleaned` dataset that we created in the last lesson._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Family_cnt</th>\n",
       "      <th>Cabin_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age     Fare  Family_cnt  Cabin_ind\n",
       "0         0       3    0  22.0   7.2500           1          0\n",
       "1         1       1    1  38.0  71.2833           1          1\n",
       "2         1       3    1  26.0   7.9250           0          0\n",
       "3         1       1    1  35.0  53.1000           1          1\n",
       "4         0       3    0  35.0   8.0500           0          0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "titanic = pd.read_csv('../titanic_cleaned.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train, validation, and test set\n",
    "\n",
    "![Split Data](img/split_data.png)\n",
    "\n",
    "_We start by splitting our data into our features (the fields used to make a prediction) and our labels or target variable (in our case that's whether somebody survived or not)._\n",
    "\n",
    "_Then we will call `train test split` method and first we need to pass in our features, then we'll pass in our labels. Now, this is a good point to call out that ideally we want to split features and labels into three separate data sets (training, test, and validation). Unfortunately, `train test split` can only handle splitting one dataset into two. So we're going to do our split in two passes through `train test split`._\n",
    "\n",
    "\n",
    "_So for our first pass we'll tell it to allocate 40% of the data to the test set. That will leave the 60% we want for the training set. Then just set `random state` (initialization seed for randomizer). It's important to note that the ordering of the output is important. It will first take the features and split it in two - so that will be `X train` and `X test` and then take the labels and split it in two and that will be `y train` and `y test`._\n",
    "\n",
    "_Now we have 60% of our data in train and 40% in set. So lets copy this and call it again and we'll pass in `X test` and `y test` and split it in half - that will give us our 20% for validation and 20% for test set. We'll update the names that we're writing out to._\n",
    "\n",
    "Just to reiterate, `train test split` can't handle splitting data into three datasets, it can only do two. So we'll handle this in two steps. Allocate 60% to training and 40% to what it's calling \"test\". Then we will take that 40% and split it in half in a second step and that will give us our 60% training, 20% validation, 20% test set._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = titanic.drop('Survived', axis=1)\n",
    "labels = titanic['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Now, lets quickly take a look at the length of each of these datasets to make sure that 60% went to train and 20% to each test and validation. So print out the length of `labels` (full dataset), length of `y train`, length of `y val`, and length of `y test`._\n",
    "\n",
    "_And we can confirm that it's split out the way we expected. We didn't have the right number for test and validation to be exactly equal so there is one more in the validation set but that's not a big deal._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 534 178 179\n"
     ]
    }
   ],
   "source": [
    "print(len(labels), len(y_train), len(y_test), len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out all data\n",
    "\n",
    "_Lastly, lets write these all out so to make sure we're using the exact same training, validation, and test set as we're exploring various algorithms in the next few sections._\n",
    "\n",
    "_Pandas has a really great built in method called `to csv` to write datafarmes out to CSV files. We include `index=False` here because the index in this dataset isn't really meaningful._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('../train_features.csv', index=False)\n",
    "X_val.to_csv('../val_features.csv', index=False)\n",
    "X_test.to_csv('../test_features.csv', index=False)\n",
    "\n",
    "y_train.to_csv('../train_labels.csv', index=False)\n",
    "y_val.to_csv('../val_labels.csv', index=False)\n",
    "y_test.to_csv('../test_labels.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
