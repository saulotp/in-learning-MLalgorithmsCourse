{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines: Hyperparameters\n",
    "\n",
    "Import [Support Vector Machines](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) from `sklearn` and explore the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Support Vector Machines Algorithm\n",
    "\n",
    "_Welcome back to the third lesson in the Support Vector Machines chapter. We've learned about what SVM is and when we should use it in that last couple lessons. Now we're going to dive into the actual details to prepare to actually fit a model in the next lesson._\n",
    "\n",
    "_We're going to start with importing Support Vector Machines, taking a look at that model object, and then we will explore some key hyperparameters_\n",
    "\n",
    "_We will call from `sklearn.svm` import `SVC` (Support Vector Classifier). Then we will just call that `SVC` object_\n",
    "\n",
    "_So this is all the potential hyperparameters we could tune. There's a lot here but just as the case was for `Logistic Regression` - compared to other algorithms this is actually a somewhat limited list. With that said, we're only going to focus on **twos** hyperparameters here._\n",
    "\n",
    "_Just as the case was for `Logistic Regression` we're going to focus on the `C` hyperparameter, again you will see it has a default value of 1.0. There is an important different between this `C` hyperparameter and the one we explored for `Logistic Regression` though - we'll cover that in just a minute. The other hyperparameter we'll dig into is the `kernel` hyperparameter - that's related to the kernel trick we talked about in the first lesson._\n",
    "\n",
    "_Now, once more before we dig into these hyperparameters, I just wanted to show that `SVC` has the same API as `Logistic Regression`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Just like `Logistic Regression`, you'll see there is this simple `fit` and `predict` method that are consistent across all algorithms. Ok, lets dive into these hyperparameters._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_cache',\n",
       " '_abc_negative_cache',\n",
       " '_abc_negative_cache_version',\n",
       " '_abc_registry',\n",
       " '_check_proba',\n",
       " '_compute_kernel',\n",
       " '_decision_function',\n",
       " '_dense_decision_function',\n",
       " '_dense_fit',\n",
       " '_dense_predict',\n",
       " '_dense_predict_proba',\n",
       " '_estimator_type',\n",
       " '_get_coef',\n",
       " '_get_param_names',\n",
       " '_impl',\n",
       " '_pairwise',\n",
       " '_predict_log_proba',\n",
       " '_predict_proba',\n",
       " '_sparse_decision_function',\n",
       " '_sparse_fit',\n",
       " '_sparse_kernels',\n",
       " '_sparse_predict',\n",
       " '_sparse_predict_proba',\n",
       " '_validate_for_predict',\n",
       " '_validate_targets',\n",
       " '_warn_from_fit_status',\n",
       " 'coef_',\n",
       " 'decision_function',\n",
       " 'fit',\n",
       " 'get_params',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'score',\n",
       " 'set_params']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
