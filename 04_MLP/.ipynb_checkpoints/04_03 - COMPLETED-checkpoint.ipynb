{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron: Hyperparameters\n",
    "\n",
    "Import [`MLPClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier) and [`MLPRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor) from `sklearn` and explore the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Multilayer Perceptron Algorithm for Classification & Regression\n",
    "\n",
    "_Welcome back to the third lesson in the Multilayer Perceptron chapter. We've learned about what it is and when we should use it and now we're going to dive into the actual details to prepare to actually fit a model in the next lesson._\n",
    "\n",
    "_Lets start by Support Vector Machines, taking a look at that model object, and then we will explore some key hyperparameters_\n",
    "\n",
    "_Lets start by importing both `MLPRegressor` and `MLPClassifier` from `sklearn.neural_network`_\n",
    "\n",
    "_So here are all of the potential hyperparameters we could tune. Remember in the last two chapters I mentioned how `Logistic Regression` and `SVM` had a fairly limited set and then in the last lesson I said there are a number of hyperparameters to tune to get this right. Perhaps you understand why when you see this._\n",
    "\n",
    "_With that said, we're going to select **three** hyperparameters to focus on here._\n",
    "\n",
    "_Those three are `hidden layer size`, `activation function`, and `learning rate`. Lets jump over to slides to explore those a little bit more._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "\n",
    "print(MLPRegressor())\n",
    "print(MLPClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
